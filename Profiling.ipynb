{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA on Colab\n",
        "This Colab notebook shows how you can not only run your CUDA code on Colab but also use it profile them. It includes a simple vector add template code for both **CUDA events** for quick execution time mertrics and **Nsight Compute (`ncu `)** for profiling.\n",
        "I wish you success in reaching SOL with your kernels faster!\n"
      ],
      "metadata": {
        "id": "LhJcQ17UDYtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "wget https://developer.nvidia.com/downloads/assets/tools/secure/nsight-systems/2025_3/NsightSystems-linux-cli-public-2025.3.1.90-3582212.deb\n",
        "dpkg -i NsightSystems-linux-cli-public-2025.3.1.90-3582212.deb"
      ],
      "metadata": {
        "id": "bkHRaEz-vRet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a33207e1-ed3b-48c2-938e-28bc19921786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-12 11:48:05--  https://developer.nvidia.com/downloads/assets/tools/secure/nsight-systems/2025_3/NsightSystems-linux-cli-public-2025.3.1.90-3582212.deb\n",
            "Resolving developer.nvidia.com (developer.nvidia.com)... 23.45.207.91, 23.45.207.74\n",
            "Connecting to developer.nvidia.com (developer.nvidia.com)|23.45.207.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://developer.download.nvidia.com/assets/tools/secure/nsight-systems/2025_3/NsightSystems-linux-cli-public-2025.3.1.90-3582212.deb?__token__=exp=1754999885~hmac=e5ffcbddd1839a7b40c32bf05c84b76c932264148c1353e56a1372c34c214e77 [following]\n",
            "--2025-08-12 11:48:05--  https://developer.download.nvidia.com/assets/tools/secure/nsight-systems/2025_3/NsightSystems-linux-cli-public-2025.3.1.90-3582212.deb?__token__=exp=1754999885~hmac=e5ffcbddd1839a7b40c32bf05c84b76c932264148c1353e56a1372c34c214e77\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 23.215.7.31, 23.215.7.4, 23.215.7.5, ...\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|23.215.7.31|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 175210028 (167M) [application/x-deb]\n",
            "Saving to: ‘NsightSystems-linux-cli-public-2025.3.1.90-3582212.deb’\n",
            "\n",
            "NsightSystems-linux 100%[===================>] 167.09M  7.35MB/s    in 26s     \n",
            "\n",
            "2025-08-12 11:48:33 (6.47 MB/s) - ‘NsightSystems-linux-cli-public-2025.3.1.90-3582212.deb’ saved [175210028/175210028]\n",
            "\n",
            "Selecting previously unselected package nsight-systems-cli-2025.3.1.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack NsightSystems-linux-cli-public-2025.3.1.90-3582212.deb ...\n",
            "Unpacking nsight-systems-cli-2025.3.1 (2025.3.1.90-253135822126v0) ...\n",
            "Setting up nsight-systems-cli-2025.3.1 (2025.3.1.90-253135822126v0) ...\n",
            "update-alternatives: using /opt/nvidia/nsight-systems-cli/2025.3.1/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in auto mode\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q34W9YkB1aGt",
        "outputId": "cd34eda6-2004-47fd-a612-e004850273f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EplLgJqC1cYc",
        "outputId": "a99e0faf-400b-4781-b68e-eb054f7cb975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA (R) Nsight Compute Command Line Profiler\n",
            "Copyright (c) 2018-2024 NVIDIA Corporation\n",
            "Version 2024.2.1.0 (build 34372528) (public-release)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA Events\n",
        "In the code below, we use **CUDA events** to measure kernel execution time.\n",
        "The kernel is run multiple times, and the average for a stable and accurate measurement , this is standard practice in GPU benchmarking .\n",
        "\n",
        "CUDA events are GPU-side timestamps. We create two events (start, stop), record them before and after the kernel launch, then use cudaEventElapsedTime() to get the duration. Because the timing is done on the GPU, it excludes CPU scheduling delays and unrelated host code.\n",
        "\n",
        "*NOTE:*\n",
        "The kernel launch is in solve() instead of main() directly only to match leetGPU submission blueprint ."
      ],
      "metadata": {
        "id": "eZQd5dcMBB31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "code = r\"\"\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define BLOCK_DIM 256\n",
        "\n",
        "__global__ void vector_add(const float* __restrict__ A, const float* __restrict__ B, float* __restrict__ C, int N) {\n",
        "    size_t tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    size_t stride = blockDim.x * gridDim.x;\n",
        "    size_t vec_size = N >> 2;\n",
        "\n",
        "    const float4* A4 = reinterpret_cast<const float4*>(A);\n",
        "    const float4* B4 = reinterpret_cast<const float4*>(B);\n",
        "    float4* C4 = reinterpret_cast<float4*>(C);\n",
        "\n",
        "    for (size_t i = tid; i < vec_size; i += stride) {\n",
        "        float4 va = __ldg(&A4[i]);\n",
        "        float4 vb = __ldg(&B4[i]);\n",
        "        float4 vc;\n",
        "        vc.x = va.x + vb.x;\n",
        "        vc.y = va.y + vb.y;\n",
        "        vc.z = va.z + vb.z;\n",
        "        vc.w = va.w + vb.w;\n",
        "        C4[i] = vc;\n",
        "    }\n",
        "\n",
        "    int tail = N % 4;\n",
        "    int base = N - tail;\n",
        "\n",
        "    if (tid < tail) {\n",
        "        C[base + tid] = __ldg(&A[base + tid]) + __ldg(&B[base + tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" void solve(const float* A, const float* B, float* C, int N) {\n",
        "    int threadsPerBlock = BLOCK_DIM;\n",
        "    int blocksPerGrid = max(1, (N/4 + threadsPerBlock - 1) / threadsPerBlock);\n",
        "    vector_add<<<blocksPerGrid, threadsPerBlock>>>(A, B, C, N);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    size_t total_elements = 10000;\n",
        "    size_t total_bytes = total_elements * sizeof(float);\n",
        "\n",
        "    float* h_A = (float*)malloc(total_bytes);\n",
        "    float* h_B = (float*)malloc(total_bytes);\n",
        "    float* h_C = (float*)malloc(total_bytes);\n",
        "\n",
        "    for (size_t i = 0; i < total_elements; ++i) {\n",
        "        h_A[i] = 1.0f;\n",
        "        h_B[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, total_bytes);\n",
        "    cudaMalloc(&d_B, total_bytes);\n",
        "    cudaMalloc(&d_C, total_bytes);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, total_bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, total_bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // -------------------------------------------------------------------\n",
        "    // CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    int runs = 10;\n",
        "    cudaEventRecord(start);\n",
        "    for (int i = 0; i < runs; i++) {\n",
        "        solve(d_A, d_B, d_C, total_elements);\n",
        "    }\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float total_ms = 0;\n",
        "    cudaEventElapsedTime(&total_ms, start, stop);\n",
        "    // Compute average per run\n",
        "    float avg_ms = total_ms / runs;\n",
        "    //------------------------------------------------------------------------\n",
        "    cudaMemcpy(h_C, d_C, total_bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    std::cout << \"First 10 results:\\n\";\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        std::cout << h_C[i] << \" \";\n",
        "    }\n",
        "    std::cout << \"Average kernel time: \" << avg_ms << \" ms\\n\";\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "HyF_do940ij5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"vec1.cu\", \"w\") as f:\n",
        "    f.write(code)"
      ],
      "metadata": {
        "id": "0YC6V2XJ7KyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O2 -lineinfo -arch=sm_75 -o vec1_ vec1.cu"
      ],
      "metadata": {
        "id": "n5hOrXck1kpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vec1_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8PrTP3V2EhL",
        "outputId": "9cbcfb11-aec8-486b-cd80-9afc4f7caee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 results:\n",
            "2 2 2 2 2 2 2 2 2 2 Average kernel time: 0.0139584 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nsight Compute\n",
        "\n",
        "Below is the same code as above, except without CUDA events — we don’t need them here because **`ncu`** provides execution time and far more detailed metrics.\n",
        "\n",
        "Compile with the `-lineinfo` flag. This allows Nsight Compute to show a side-by-side comparison of your source code and the generated low-level instructions in the **Source** section of the GUI.\n",
        "\n",
        "I also recommend watching the GPU Mode Nsight Compute tutorial: [NVIDIA GPU Profiling](https://youtu.be/F_BazucyCMw?si=sMiZRy_erDidhQXT) for a detailed walkthrough on interpreting metrics, navigating the deatil and source view, and optimizing kernels to the SOL (Speed of Light).\n"
      ],
      "metadata": {
        "id": "rz8Z2uweD4Hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "code2 = r\"\"\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define BLOCK_DIM 256\n",
        "\n",
        "__global__ void vector_add(const float* __restrict__ A, const float* __restrict__ B, float* __restrict__ C, int N) {\n",
        "    size_t tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    size_t stride = blockDim.x * gridDim.x;\n",
        "    size_t vec_size = N >> 2;\n",
        "\n",
        "    const float4* A4 = reinterpret_cast<const float4*>(A);\n",
        "    const float4* B4 = reinterpret_cast<const float4*>(B);\n",
        "    float4* C4 = reinterpret_cast<float4*>(C);\n",
        "\n",
        "    for (size_t i = tid; i < vec_size; i += stride) {\n",
        "        float4 va = __ldg(&A4[i]);\n",
        "        float4 vb = __ldg(&B4[i]);\n",
        "        float4 vc;\n",
        "        vc.x = va.x + vb.x;\n",
        "        vc.y = va.y + vb.y;\n",
        "        vc.z = va.z + vb.z;\n",
        "        vc.w = va.w + vb.w;\n",
        "        C4[i] = vc;\n",
        "    }\n",
        "\n",
        "    int tail = N % 4;\n",
        "    int base = N - tail;\n",
        "\n",
        "    if (tid < tail) {\n",
        "        C[base + tid] = __ldg(&A[base + tid]) + __ldg(&B[base + tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" void solve(const float* A, const float* B, float* C, int N) {\n",
        "    int threadsPerBlock = BLOCK_DIM;\n",
        "    int blocksPerGrid = max(1, (N/4 + threadsPerBlock - 1) / threadsPerBlock);\n",
        "    vector_add<<<blocksPerGrid, threadsPerBlock>>>(A, B, C, N);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    size_t total_elements = 10000;\n",
        "    size_t total_bytes = total_elements * sizeof(float);\n",
        "\n",
        "    float* h_A = (float*)malloc(total_bytes);\n",
        "    float* h_B = (float*)malloc(total_bytes);\n",
        "    float* h_C = (float*)malloc(total_bytes);\n",
        "\n",
        "    for (size_t i = 0; i < total_elements; ++i) {\n",
        "        h_A[i] = 1.0f;\n",
        "        h_B[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, total_bytes);\n",
        "    cudaMalloc(&d_B, total_bytes);\n",
        "    cudaMalloc(&d_C, total_bytes);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, total_bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, total_bytes, cudaMemcpyHostToDevice);\n",
        "    solve(d_A, d_B, d_C, total_elements);\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaMemcpy(h_C, d_C, total_bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    std::cout << \"First 10 results:\\n\";\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        std::cout << h_C[i] << \" \";\n",
        "    }\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "4FT3QKUX_04Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"vec2.cu\", \"w\") as f:\n",
        "    f.write(code2)"
      ],
      "metadata": {
        "id": "_ycQ7yJmAr4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O2 -lineinfo -arch=sm_75 -o vec2_ vec2.cu"
      ],
      "metadata": {
        "id": "GTrACixoAzDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vec2_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beN7-BOOAzPW",
        "outputId": "7a40d47f-39f2-4668-81cf-4ea358ab42f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 results:\n",
            "2 2 2 2 2 2 2 2 2 2 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu --set full -o vecprofile2 -f ./vec2_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNYfLPaT46AN",
        "outputId": "519c640a-5c20-41ed-bf05-1234c6186cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 2116 (/content/vec2_)\n",
            "==PROF== Profiling \"vector_add\" - 0: 0%....50%....100% - 30 passes\n",
            "First 10 results:\n",
            "2 2 2 2 2 2 2 2 2 2 ==PROF== Disconnected from process 2116\n",
            "==PROF== Report: /content/vecprofile2.ncu-rep\n"
          ]
        }
      ]
    }
  ]
}